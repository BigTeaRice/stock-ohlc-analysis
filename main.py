# ------------------------------
# å°å…¥æ‰€éœ€å¥—ä»¶
# ------------------------------
import pandas as pd
import mplfinance as mpf
from pathlib import Path
from datetime import datetime
import sys

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ•°æ®é¢„å¤„ç†å‡½æ•°ï¼ˆç»Ÿä¸€åˆ—åã€å»é‡ã€å»ç¼ºå¤±ã€è®¡ç®—æŒ‡æ ‡ï¼‰
    
    å‚æ•°:
        df (pd.DataFrame): åŸå§‹æ•°æ®ï¼ˆéœ€åŒ…å«Date/Open/High/Low/Close/Volumeåˆ—ï¼‰
    è¿”å›:
        pd.DataFrame: å¤„ç†åçš„æ•°æ®
    """
    try:
        # -------------------- æ­¥éª¤1ï¼šç»Ÿä¸€åˆ—åï¼ˆè§£å†³å¤§å°å†™/ç©ºæ ¼é—®é¢˜ï¼‰ --------------------
        # å®šä¹‰ç›®æ ‡åˆ—åï¼ˆä»£ç ä¸­ä½¿ç”¨çš„æ ‡å‡†åˆ—åï¼‰
        target_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
        # å°†åŸå§‹åˆ—åè½¬ä¸ºå°å†™ï¼ŒåŒ¹é…ç›®æ ‡åˆ—åï¼ˆæ¯”å¦‚'open'â†’'Open'ï¼Œ'High 'â†’'High'ï¼‰
        col_mapping = {col.strip().lower(): target_col for target_col in target_cols 
                       for col in df.columns if col.strip().lower() == target_col}
        # ä»…ä¿ç•™ç›®æ ‡åˆ—ï¼ˆé¿å…æ— å…³åˆ—å¹²æ‰°ï¼‰
        df = df.rename(columns=col_mapping)[target_cols]
        
        # -------------------- æ­¥éª¤2ï¼šæ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨ --------------------
        missing_cols = [col for col in target_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"æ•°æ®ç¼ºå¤±å¿…è¦åˆ—ï¼š{missing_cols}ï¼Œè¯·æ£€æŸ¥CSVæ–‡ä»¶åˆ—åï¼")
        
        # -------------------- æ­¥éª¤3ï¼šæ•°æ®æ¸…æ´— --------------------
        # å»é™¤é‡å¤ç´¢å¼•ï¼ˆåŒä¸€æ—¥æœŸå¤šæ¡æ•°æ®ï¼Œä¿ç•™æœ€åä¸€æ¡ï¼‰
        df = df[~df.index.duplicated(keep='last')]
        # å»é™¤å…³é”®æ•°æ®ç¼ºå¤±çš„è¡Œï¼ˆOpen/High/Low/Closeä¸èƒ½ä¸ºNaNï¼‰
        df = df.dropna(subset=['Open', 'High', 'Low', 'Close'])
        # ç¡®ä¿æ”¶ç›˜ä»·å¤§äº0ï¼ˆé¿å…æ¶¨è·Œå¹…è®¡ç®—é”™è¯¯ï¼‰
        df = df[df['Close'] > 0]
        
        # -------------------- æ­¥éª¤4ï¼šè®¡ç®—è¡ç”ŸæŒ‡æ ‡ --------------------
        # æˆªå–æœ€è¿‘150ä¸ªäº¤æ˜“æ—¥ï¼ˆè‡ªåŠ¨è·³è¿‡éäº¤æ˜“æ—¥ï¼‰
        df = df.last('150D')
        if df.empty:
            raise ValueError("æˆªå–150ä¸ªäº¤æ˜“æ—¥åæ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´ï¼")
        
        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆé˜²å¾¡æ€§å¤„ç†é™¤é›¶é”™è¯¯ï¼‰
        prev_close = df['Close'].shift(1)
        df['æ¶¨å¹…(%)'] = ((df['Close'] - prev_close) / prev_close * 100).round(2)
        df.loc[prev_close == 0, 'æ¶¨å¹…(%)'] = 0.0  # å‰ä¸€æ—¥æ”¶ç›˜ä»·ä¸º0æ—¶æ¶¨å¹…è®¾ä¸º0
        
        # è®¡ç®—å¤šå‘¨æœŸå‡çº¿ï¼ˆé»˜è®¤5/10/20/30/60ï¼‰
        ma_windows = [5, 10, 20, 30, 60]
        for window in ma_windows:
            df[f'MA{window}'] = df['Close'].rolling(window=window, min_periods=1).mean()
        
        return df.reset_index(drop=False)  # ä¿ç•™Dateåˆ—ï¼ˆåç»­ç»˜å›¾éœ€è¦ç´¢å¼•ï¼‰
    
    except Exception as e:
        print(f"æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)  # é¢„å¤„ç†å¤±è´¥ç›´æ¥é€€å‡º


def plot_stock_kline(csv_path: str, 
                     title: str = "è‚¡ç¥¨Kçº¿å›¾", 
                     ma_windows: list = [5, 10, 20, 30, 60],
                     figsize: tuple = (14, 8)):
    """
    ç»˜åˆ¶ä¸“ä¸šè‚¡ç¥¨Kçº¿å›¾ï¼ˆå«å‡çº¿ã€æˆäº¤é‡ã€æœ€æ–°è¡Œæƒ…æ ‡æ³¨ï¼‰
    
    å‚æ•°:
        csv_path (str): è‚¡ç¥¨æ•°æ®CSVæ–‡ä»¶è·¯å¾„
        title (str): å›¾è¡¨æ ‡é¢˜
        ma_windows (list): å‡çº¿å‘¨æœŸåˆ—è¡¨
        figsize (tuple): å›¾è¡¨å°ºå¯¸ï¼ˆå®½, é«˜ï¼‰
    """
    try:
        # -------------------- æ­¥éª¤1ï¼šè¯»å–å¹¶é¢„å¤„ç†æ•°æ® --------------------
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(csv_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š
è·¯å¾„ï¼š{csv_path}")
        
        # è¯»å–CSVï¼ˆä»…åŠ è½½å¿…è¦åˆ—ï¼Œé¿å…æ— å…³æ•°æ®å¹²æ‰°ï¼‰
        raw_df = pd.read_csv(
            csv_path,
            parse_dates=['Date'],       # å°è¯•è§£æDateåˆ—
            index_col='Date',           # è®¾ä¸ºç´¢å¼•ï¼ˆæ–¹ä¾¿åç»­å¤„ç†ï¼‰
            usecols=lambda col: col.strip().lower() in ['date', 'open', 'high', 'low', 'close', 'volume'],  # åŒ¹é…åˆ—å
            na_values=['', 'N/A', 'NaN', 'æ— æ•ˆæ—¥æœŸ'],  # æ ‡è®°æ— æ•ˆå€¼
            dayfirst=True,              # ä¼˜å…ˆè§£æä¸ºDD/MM/YYYY
            date_parser=lambda x: datetime.strptime(x, "%d/%m/%Y")  # å¼ºåˆ¶è§£ææ ¼å¼
        )
        
        # é¢„å¤„ç†æ•°æ®
        df = preprocess_data(raw_df)
        df.set_index('Date', inplace=True)  # æ¢å¤Dateä¸ºç´¢å¼•ï¼ˆmplfinanceè¦æ±‚ï¼‰
        
        # -------------------- æ­¥éª¤2ï¼šé…ç½®å›¾è¡¨æ ·å¼ --------------------
        # è‡ªå®šä¹‰é¢œè‰²ï¼ˆçº¢æ¶¨ç»¿è·Œï¼‰
        market_colors = mpf.make_marketcolors(
            up='red', down='green', inherit=True
        )
        # è‡ªå®šä¹‰å›¾è¡¨é£æ ¼
        style = mpf.make_mpf_style(
            marketcolors=market_colors,
            gridstyle='--', gridcolor='lightgray',
            y_on_right=True,  # Yè½´åœ¨å³ä¾§
            facecolor='white',
            rc={'font.size': 12, 'font.family': 'SimHei', 'axes.unicode_minus': False}
        )
        
        # é…ç½®å‡çº¿æ ·å¼
        ma_styles = {
            5: {'color': 'crimson', 'width': 1.2},
            10: {'color': 'gold', 'width': 1.2},
            20: {'color': 'black', 'width': 1.5},
            30: {'color': 'darkcyan', 'width': 1.2},
            60: {'color': 'darkgreen', 'width': 1.2}
        }
        # ç”Ÿæˆå‡çº¿é™„åŠ å›¾
        add_plots = [
            mpf.make_addplot(df[f'MA{window}'], panel=0, **ma_styles.get(window, {'color': 'blue', 'width': 1}))
            for window in ma_windows
        ]
        
        # -------------------- æ­¥éª¤3ï¼šç»˜åˆ¶Kçº¿å›¾ --------------------
        fig, axes = mpf.plot(
            df,
            type='candle',       # èœ¡çƒ›å›¾
            style=style,         # è‡ªå®šä¹‰é£æ ¼
            addplot=add_plots,   # æ·»åŠ å‡çº¿
            title=title,         # å›¾è¡¨æ ‡é¢˜
            ylabel='ä»·æ ¼ï¼ˆå…ƒï¼‰',  # Yè½´æ ‡ç­¾
            volume=True,         # æ˜¾ç¤ºæˆäº¤é‡
            ylabel_lower='æˆäº¤é‡ï¼ˆæ‰‹ï¼‰',  # æˆäº¤é‡Yè½´æ ‡ç­¾
            datetime_format='%Y-%m-%d',  # æ—¥æœŸæ ¼å¼
            returnfig=True,      # è¿”å›Figureå¯¹è±¡ï¼ˆç”¨äºæ ‡æ³¨ï¼‰
            figsize=figsize      # å›¾è¡¨å°ºå¯¸
        )
        
        # -------------------- æ­¥éª¤4ï¼šæ·»åŠ æœ€æ–°è¡Œæƒ…æ ‡æ³¨ --------------------
        latest = df.iloc[-1]
        prev_day = df.iloc[-2] if len(df) >= 2 else latest
        
        # å·¦ä¸Šè§’ï¼šä»Šæ—¥è¡Œæƒ…
        fig.text(
            0.05, 0.95,  # ä½ç½®ï¼ˆå·¦ä¸Šè§’ï¼‰
            f"ä»Šæ—¥è¡Œæƒ…
"
            f"æ”¶ç›˜ä»·: {latest['Close']:.2f} å…ƒ
"
            f"å¼€ç›˜ä»·: {latest['Open']:.2f} å…ƒ
"
            f"æœ€é«˜ä»·: {latest['High']:.2f} å…ƒ
"
            f"æœ€ä½ä»·: {latest['Low']:.2f} å…ƒ
"
            f"æ¶¨è·Œå¹…: {latest['æ¶¨å¹…(%)']:.2f}%
"
            f"æˆäº¤é‡: {latest['Volume']:,} æ‰‹",
            color='red' if latest['æ¶¨å¹…(%)'] > 0 else 'green',
            bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray')
        )
        
        # å³ä¸Šè§’ï¼šå‡çº¿ä¸æ•°æ®æ—¶é—´
        ma_text = "
".join([f"MA{w}: {latest[f'MA{w}']:.2f} å…ƒ" for w in ma_windows])
        right_text = f"æ•°æ®æ—¶é—´: {latest.name.strftime('%Y-%m-%d')}
{ma_text}"
        fig.text(
            0.95, 0.95,  # ä½ç½®ï¼ˆå³ä¸Šè§’ï¼‰
            right_text,
            color='black',
            bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'),
            ha='right'
        )
        
        # æ˜¾ç¤ºå›¾è¡¨
        mpf.show()
        
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå¤±è´¥ï¼š{str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    # ------------------- ä½¿ç”¨ç¤ºä¾‹ -------------------
    csv_file = r"d:\Users\felix\data\600519.csv"  # æ›¿æ¢ä¸ºä½ çš„CSVè·¯å¾„
    plot_stock_kline(
        csv_path=csv_file,
        title="è´µå·èŒ…å°ï¼ˆ600519ï¼‰150å¤©Kçº¿å›¾",
        ma_windows=[5, 10, 20, 30, 60],
        figsize=(14, 8)
    )# ------------------------------
# å°å…¥æ‰€éœ€å¥—ä»¶
# ------------------------------
import pandas as pd
import plotly.graph_objects as go
import yfinance as yf
from datetime import datetime
import os
import traceback
import pytz
import time

# ------------------------------
# å…¨åŸŸåƒæ•¸è¨­å®š
# ------------------------------
TICKER = "0700.HK"  # æ¸¯è‚¡æ­£ç¡®ä»£ç ï¼ˆ0700.HKï¼‰
START_DATE = "2004-06-16"  # è…¾è®¯ä¸Šå¸‚æ—¥æœŸ
END_DATE = datetime.today().strftime("%Y-%m-%d")
CACHE_DIR = "data"
CACHE_FILE = os.path.join(CACHE_DIR, f"{TICKER.replace('.', '-')}.csv")
HONG_KONG_TZ = pytz.timezone('Asia/Hong_Kong')
MAX_RETRIES = 3
RETRY_DELAY = 5

# ------------------------------
# å‡½å¼å®šç¾©ï¼šæ•¸æ“šç²å–èˆ‡ç·©å­˜
# ------------------------------
def fetch_and_cache_data(ticker, start_date, end_date, cache_dir, cache_file, tz):
    try:
        os.makedirs(cache_dir, exist_ok=True)

        # è®€å–ç·©å­˜ï¼ˆè‹¥å­˜åœ¨ï¼‰
        if os.path.exists(cache_file):
            print(f"ğŸ“‚ å˜—è©¦è®€å–ç·©å­˜ï¼š{cache_file}")
            df = pd.read_csv(cache_file, parse_dates=["Date"], encoding='utf-8')
            if df.empty:
                raise ValueError("ç·©å­˜æ•¸æ“šç‚ºç©º")
            # æª¢æŸ¥ç·©å­˜åˆ—åæ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
            required_cols = ["Open", "High", "Low", "Close"]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise ValueError(f"ç·©å­˜ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}")
            # é©—è­‰æ™‚é–“ç¯„åœ
            min_date = df["Date"].min().strftime('%Y-%m-%d')
            max_date = df["Date"].max().strftime('%Y-%m-%d')
            if min_date >= start_date and max_date <= end_date:
                print(f"âœ… ç·©å­˜æœ‰æ•ˆï¼ˆ{min_date} è‡³ {max_date}ï¼‰")
                return df
            else:
                print("âŒ ç·©å­˜æ™‚é–“ç¯„åœä¸åŒ¹é…ï¼Œé‡æ–°ä¸‹è¼‰")

        # ä¸‹è¼‰æ•¸æ“šï¼ˆyfinance é»˜èªè¿”å›å¤§å¯«åˆ—åï¼šOpen/High/Low/Closeï¼‰
        for attempt in range(MAX_RETRIES):
            try:
                print(f"â³ ä¸‹è¼‰æ•¸æ“šï¼ˆç¬¬ {attempt+1}/{MAX_RETRIES} æ¬¡ï¼‰")
                df = yf.download(
                    tickers=ticker,
                    start=start_date,
                    end=end_date,
                    progress=False,
                    auto_adjust=True,
                    actions=False
                )
                if df.empty:
                    raise ValueError("Yahoo Finance ç„¡æ•¸æ“š")
                # æª¢æŸ¥ä¸‹è¼‰çš„åˆ—å
                required_cols = ["Open", "High", "Low", "Close"]
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    raise ValueError(f"ä¸‹è¼‰æ•¸æ“šç¼ºå°‘åˆ—ï¼š{missing_cols}")
                # æ™‚å€è½‰æ›
                df.index = df.index.tz_localize('UTC').tz_convert(tz)
                df = df.reset_index()
                # ä¿å­˜ç·©å­˜
                df.to_csv(cache_file, index=False, encoding='utf-8')
                print(f"ğŸ’¾ æ•¸æ“šä¿å­˜åˆ°ç·©å­˜ï¼š{cache_file}")
                return df

            except Exception as e:
                print(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼ˆç¬¬ {attempt+1} æ¬¡ï¼‰ï¼š{str(e)}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
                else:
                    raise RuntimeError(f"ä¸‹è¼‰å¤±æ•—ï¼ˆè¶…é {MAX_RETRIES} æ¬¡ï¼‰") from e

    except Exception as e:
        error_msg = f"æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å‡½å¼ï¼šfetch_and_cache_data
éŒ¯èª¤ï¼š{str(e)}
å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "w", encoding='utf-8') as f:
            f.write(error_msg)
        raise

# ------------------------------
# å‡½å¼å®šç¾©ï¼šæ•¸æ“šé è™•ç†ï¼ˆä¿®å¾©åˆ—åå•é¡Œï¼‰
# ------------------------------
def preprocess_data(df):
    try:
        print("ğŸ”„ é–‹å§‹é è™•ç†æ•¸æ“š...")
        # 1. å»é™¤åˆ—åå‰å¾Œç©ºæ ¼ï¼ˆè§£æ±ºã€ŒOpen ã€æˆ–ã€Œ openã€ç­‰å•é¡Œï¼‰
        df.columns = df.columns.str.strip()
        print(f"âœ… åˆ—åè™•ç†å®Œæˆï¼š{df.columns.tolist()}")

        # 2. æª¢æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆOpen/High/Low/Closeï¼‰
        required_cols = ["Open", "High", "Low", "Close"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"æ•¸æ“šç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}ï¼å¯¦éš›åˆ—åï¼š{df.columns.tolist()}")

        # 3. è½‰æ›æ—¥æœŸæ¬„ä½ä¸¦æ’åº
        df["Date"] = pd.to_datetime(df["Date"], utc=True).dt.tz_convert(HONG_KONG_TZ)
        df = df.sort_values(by="Date").reset_index(drop=True)

        # 4. è™•ç†ç¼ºå¤±å€¼
        initial_count = len(df)
        df = df.dropna(subset=required_cols)
        deleted_rows = initial_count - len(df)
        if deleted_rows > 0:
            print(f"âš ï¸ åˆªé™¤ {deleted_rows} è¡Œç¼ºå¤±å€¼æ•¸æ“š")

        # 5. é©—è­‰æ•¸æ“šé‡
        if len(df) < 2:
            raise ValueError("é è™•ç†å¾Œæ•¸æ“šä¸è¶³ï¼ˆå°‘æ–¼ 2 è¡Œï¼‰")

        print("âœ… é è™•ç†å®Œæˆï¼")
        return df

    except Exception as e:
        error_msg = f"æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å‡½å¼ï¼špreprocess_data
éŒ¯èª¤ï¼š{str(e)}
å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "a", encoding='utf-8') as f:
            f.write(error_msg)
        raise

# ------------------------------
# å‡½å¼å®šç¾©ï¼šç¹ªè£½åœ–è¡¨
# ------------------------------
def plot_ohlc_chart(df, ticker):
    try:
        print("ğŸ“ˆ é–‹å§‹ç¹ªè£½åœ–è¡¨...")
        df["Date_Str"] = df["Date"].dt.strftime("%Y-%m-%d")

        fig = go.Figure(data=[go.Ohlc(
            x=df["Date_Str"],
            open=df["Open"],
            high=df["High"],
            low=df["Low"],
            close=df["Close"],
            name=ticker,
            increasing_line_color='#ff0000',
            decreasing_line_color='#00ff00'
        )])

        fig.update_layout(
            title={"text": f"{ticker} æ­·å²Kç·šåœ–", "x": 0.5},
            xaxis_title="æ—¥æœŸ",
            yaxis_title="åƒ¹æ ¼ (HKD)",
            xaxis_rangeslider_visible=False,
            template="plotly_white"
        )

        output_path = "./ohlc_chart.html"
        fig.write_html(output_path, include_plotlyjs="cdn", auto_open=True)
        print(f"âœ… åœ–è¡¨ç”Ÿæˆï¼š{output_path}")

        return output_path

    except Exception as e:
        error_msg = f"æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å‡½å¼ï¼šplot_ohlc_chart
éŒ¯èª¤ï¼š{str(e)}
å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "a", encoding='utf-8') as f:
            f.write(error_msg)
        raise

# ------------------------------
# ä¸»ç¨‹å¼å…¥å£
# ------------------------------
if __name__ == "__main__":
    try:
        print("ğŸš€ é–‹å§‹é‹è¡Œç¨‹å¼...")
        # 1. ç²å–/ç·©å­˜æ•¸æ“š
        df = fetch_and_cache_data(
            ticker=TICKER,
            start_date=START_DATE,
            end_date=END_DATE,
            cache_dir=CACHE_DIR,
            cache_file=CACHE_FILE,
            tz=HONG_KONG_TZ
        )
        # æ‰“å°ä¸‹è¼‰æ•¸æ“šçš„åˆ—åï¼ˆèª¿è©¦ç”¨ï¼‰
        print(f"ğŸ“Š ä¸‹è¼‰æ•¸æ“šçš„åˆ—åï¼š{df.columns.tolist()}")

        # 2. é è™•ç†æ•¸æ“š
        processed_df = preprocess_data(df)
        # æ‰“å°é è™•ç†å¾Œçš„åˆ—åï¼ˆèª¿è©¦ç”¨ï¼‰
        print(f"ğŸ” é è™•ç†å¾Œçš„åˆ—åï¼š{processed_df.columns.tolist()}")

        # 3. ç¹ªè£½åœ–è¡¨
        plot_ohlc_chart(processed_df, TICKER)

        print("ğŸ‰ ç¨‹å¼åŸ·è¡ŒæˆåŠŸï¼")

    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—ï¼š{str(e)}")
        exit(1)
