# ------------------------------
# å…¨åŸŸåƒæ•¸è¨­å®šï¼ˆå„ªå…ˆè®€å–ç’°å¢ƒè®Šé‡ï¼‰
# ------------------------------
import os
import argparse
import pandas as pd
import plotly.graph_objects as go
import yfinance as yf
from datetime import datetime
import time
import pytz
import traceback

# 1. åŸºç¤é…ç½®ï¼ˆç’°å¢ƒè®Šé‡è¦†è“‹é»˜èªå€¼ï¼‰
TICKER = os.getenv('TICKER', '0700.HK')                  # æ¸¯è‚¡ä»£ç¢¼ï¼ˆé»˜èªé¨°è¨Šï¼‰
START_DATE = os.getenv('START_DATE', '2004-06-16')       # èµ·å§‹æ—¥æœŸï¼ˆé¨°è¨Šä¸Šå¸‚æ—¥ï¼‰
END_DATE = os.getenv('END_DATE', datetime.today().strftime("%Y-%m-%d"))  # çµæŸæ—¥æœŸï¼ˆä»Šæ—¥ï¼‰
CACHE_DIR = os.getenv('CACHE_DIR', 'stock_data')         # æ•¸æ“šç·©å­˜ç›®éŒ„ï¼ˆèˆ‡å·¥ä½œæµä¸€è‡´ï¼‰
CACHE_FILE = os.path.join(CACHE_DIR, f"{TICKER.replace('.', '-')}.csv")  # ç·©å­˜æ–‡ä»¶è·¯å¾‘ï¼ˆ0700-HK.csvï¼‰
HONG_KONG_TZ = pytz.timezone('Asia/Hong_Kong')           # é¦™æ¸¯æ™‚å€
MAX_RETRIES = 3                                          # ä¸‹è¼‰é‡è©¦æ¬¡æ•¸
RETRY_DELAY = 5                                          # é‡è©¦é–“éš”ï¼ˆç§’ï¼‰


# ------------------------------
# å‡½å¼å®šç¾©ï¼šæ•¸æ“šç²å–èˆ‡ç·©å­˜ï¼ˆå¼·åŒ–æ—¥èªŒèˆ‡é©—è­‰ï¼‰
# ------------------------------
def fetch_and_cache_data(ticker, start_date, end_date, cache_dir, cache_file, tz):
    try:
        os.makedirs(cache_dir, exist_ok=True)
        print(f"[DEBUG] ç·©å­˜ç›®éŒ„ï¼š{cache_dir}")
        print(f"[DEBUG] ç·©å­˜æ–‡ä»¶ï¼š{cache_file}")

        # 1. å˜—è©¦è®€å–ç·©å­˜
        if os.path.exists(cache_file):
            print(f"[INFO] ç™¼ç¾ç·©å­˜æ–‡ä»¶ï¼Œå˜—è©¦åŠ è¼‰...")
            df = pd.read_csv(cache_file, parse_dates=["Date"], encoding='utf-8')
            
            # é©—è­‰ç·©å­˜æœ‰æ•ˆæ€§
            if df.empty:
                raise ValueError("ç·©å­˜æ•¸æ“šç‚ºç©º")
            required_cols = ["Date", "Open", "High", "Low", "Close"]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise ValueError(f"ç·©å­˜ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}")
            
            # é©—è­‰æ™‚é–“ç¯„åœï¼ˆç·©å­˜éœ€è¦†è“‹è«‹æ±‚çš„æ™‚é–“æ®µï¼‰
            min_cache_date = df["Date"].min().strftime('%Y-%m-%d')
            max_cache_date = df["Date"].max().strftime('%Y-%m-%d')
            if not (min_cache_date <= start_date and max_cache_date >= end_date):
                raise ValueError(f"ç·©å­˜æ™‚é–“ç¯„åœä¸è¶³ï¼ˆç·©å­˜ï¼š{min_cache_date}~{max_cache_date}ï¼Œè«‹æ±‚ï¼š{start_date}~{end_date}ï¼‰")
            
            print(f"[SUCCESS] ç·©å­˜æœ‰æ•ˆï¼ˆ{min_cache_date} ~ {max_cache_date}ï¼‰")
            return df

        # 2. ä¸‹è¼‰æ•¸æ“šï¼ˆyfinanceï¼‰
        for attempt in range(MAX_RETRIES):
            try:
                print(f"[INFO] ä¸‹è¼‰æ•¸æ“šï¼ˆç¬¬{attempt+1}/{MAX_RETRIES}æ¬¡ï¼‰...")
                df = yf.download(
                    tickers=ticker,
                    start=start_date,
                    end=end_date,
                    progress=False,
                    auto_adjust=True,
                    actions=False
                )
                
                if df.empty:
                    raise ValueError("Yahoo Finance è¿”å›ç©ºæ•¸æ“š")
                
                # ä¿®å¾©åˆ—åèˆ‡ç´¢å¼•
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.droplevel(1)
                df = df.reset_index().rename(columns={'Datetime': 'Date'})
                df.columns = df.columns.str.capitalize()  # çµ±ä¸€åˆ—åï¼ˆé¦–å­—æ¯å¤§å¯«ï¼‰
                
                # é©—è­‰å¿…è¦åˆ—
                required_cols = ["Date", "Open", "High", "Low", "Close"]
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    raise ValueError(f"ä¸‹è¼‰æ•¸æ“šç¼ºå°‘åˆ—ï¼š{missing_cols}")
                
                # æ™‚å€è½‰æ›ï¼ˆUTC â†’ é¦™æ¸¯æ™‚å€ï¼‰
                df['Date'] = pd.to_datetime(df['Date']).dt.tz_localize('UTC').dt.tz_convert(tz)
                
                # ä¿å­˜ç·©å­˜
                df.to_csv(cache_file, index=False, encoding='utf-8')
                print(f"[SUCCESS] æ•¸æ“šä¿å­˜åˆ°ç·©å­˜ï¼š{cache_file}")
                return df

            except Exception as e:
                print(f"[ERROR] ä¸‹è¼‰å¤±æ•—ï¼ˆç¬¬{attempt+1}æ¬¡ï¼‰ï¼š{str(e)}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)
                else:
                    raise RuntimeError(f"ä¸‹è¼‰å¤±æ•—ï¼ˆè¶…é{MAX_RETRIES}æ¬¡ï¼‰") from e

    except Exception as e:
        # ä¿å­˜éŒ¯èª¤æ—¥èªŒ
        error_msg = f"[ERROR] æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        error_msg += f"[ERROR] å‡½å¼ï¼šfetch_and_cache_data\n"
        error_msg += f"[ERROR] éŒ¯èª¤ï¼š{str(e)}\n"
        error_msg += f"[ERROR] å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "w", encoding='utf-8') as f:
            f.write(error_msg)
        raise


# ------------------------------
# å‡½å¼å®šç¾©ï¼šæ•¸æ“šé è™•ç†ï¼ˆå¼·åŒ–é©—è­‰ï¼‰
# ------------------------------
def preprocess_data(df):
    try:
        print("[INFO] é–‹å§‹é è™•ç†æ•¸æ“š...")
        df.columns = df.columns.str.capitalize()  # ç¢ºä¿åˆ—åçµ±ä¸€

        # 1. é©—è­‰å¿…è¦åˆ—
        required_cols = ["Date", "Open", "High", "Low", "Close"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"æ•¸æ“šç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}ï¼ˆå¯¦éš›åˆ—ï¼š{df.columns.tolist()}ï¼‰")

        # 2. è½‰æ›æ—¥æœŸèˆ‡æ’åº
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values(by="Date").reset_index(drop=True)
        print(f"[DEBUG] é è™•ç†å¾Œæ•¸æ“šé‡ï¼š{len(df)} è¡Œ")
        print(f"[DEBUG] æ•¸æ“šæ™‚é–“ç¯„åœï¼š{df['Date'].min().strftime('%Y-%m-%d')} ~ {df['Date'].max().strftime('%Y-%m-%d')}")

        # 3. è™•ç†ç¼ºå¤±å€¼
        initial_count = len(df)
        df = df.dropna(subset=required_cols)
        deleted_rows = initial_count - len(df)
        if deleted_rows > 0:
            print(f"[WARNING] åˆªé™¤ {deleted_rows} è¡Œç¼ºå¤±å€¼æ•¸æ“š")

        # 4. é©—è­‰æ•¸æ“šé‡
        if len(df) < 2:
            raise ValueError("é è™•ç†å¾Œæ•¸æ“šä¸è¶³ï¼ˆå°‘æ–¼2è¡Œï¼Œç„¡æ³•ç¹ªåœ–ï¼‰")
        print("[SUCCESS] é è™•ç†å®Œæˆï¼")
        return df

    except Exception as e:
        # ä¿å­˜éŒ¯èª¤æ—¥èªŒ
        error_msg = f"[ERROR] æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        error_msg += f"[ERROR] å‡½å¼ï¼špreprocess_data\n"
        error_msg += f"[ERROR] éŒ¯èª¤ï¼š{str(e)}\n"
        error_msg += f"[ERROR] å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "a", encoding='utf-8') as f:
            f.write(error_msg)
        raise


# ------------------------------
# å‡½å¼å®šç¾©ï¼šç¹ªè£½Kç·šåœ–ï¼ˆè¼¸å‡ºåˆ°æ ¹ç›®éŒ„ï¼‰
# ------------------------------
def plot_ohlc_chart(df, ticker):
    try:
        print("[INFO] é–‹å§‹ç¹ªè£½Kç·šåœ–...")
        df["Date_Str"] = df["Date"].dt.strftime("%Y-%m-%d")

        # ç”ŸæˆKç·šåœ–
        fig = go.Figure(data=[go.Ohlc(
            x=df["Date_Str"],
            open=df["Open"],
            high=df["High"],
            low=df["Low"],
            close=df["Close"],
            name=ticker,
            increasing_line_color='#ff0000',  # ç´…æ¼²
            decreasing_line_color='#00ff00'   # ç¶ è·Œ
        )])

        # è¨­ç½®åœ–è¡¨å¸ƒå±€
        fig.update_layout(
            title={"text": f"{ticker} æ­·å²Kç·šåœ–ï¼ˆé¦™æ¸¯æ™‚å€ï¼‰", "x": 0.5},
            xaxis_title="æ—¥æœŸ",
            yaxis_title="åƒ¹æ ¼ï¼ˆæ¸¯å…ƒï¼‰",
            xaxis_rangeslider_visible=False,  # éš±è—æ»‘å¡Š
            template="plotly_white",
            width=1200,  # åœ–è¡¨å¯¬åº¦
            height=600   # åœ–è¡¨é«˜åº¦
        )

        # è¼¸å‡ºåˆ°æ ¹ç›®éŒ„ï¼ˆèˆ‡å·¥ä½œæµä¸€è‡´ï¼‰
        output_path = "./ohlc_chart.html"
        fig.write_html(output_path, include_plotlyjs="cdn", auto_open=True)
        print(f"[SUCCESS] åœ–è¡¨ç”Ÿæˆï¼š{output_path}")
        return output_path

    except Exception as e:
        # ä¿å­˜éŒ¯èª¤æ—¥èªŒ
        error_msg = f"[ERROR] æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        error_msg += f"[ERROR] å‡½å¼ï¼šplot_ohlc_chart\n"
        error_msg += f"[ERROR] éŒ¯èª¤ï¼š{str(e)}\n"
        error_msg += f"[ERROR] å †ç–Šï¼š{traceback.format_exc()}"
        with open("error.log", "a", encoding='utf-8') as f:
            f.write(error_msg)
        raise


# ------------------------------
# ä¸»ç¨‹å¼å…¥å£ï¼ˆè§£æå‘½ä»¤è¡Œåƒæ•¸ï¼‰
# ------------------------------
if __name__ == "__main__":
    try:
        # 1. è§£æå‘½ä»¤è¡Œåƒæ•¸ï¼ˆæ”¯æŒdebug_modeï¼‰
        parser = argparse.ArgumentParser(description="ç”Ÿæˆé¨°è¨Šè‚¡ç¥¨Kç·šåœ–")
        parser.add_argument("--debug_mode", action="store_true", help="å•Ÿç”¨è©³ç´°èª¿è©¦æ—¥èªŒ")
        args = parser.parse_args()

        # 2. åˆå§‹åŒ–èª¿è©¦æ¨¡å¼
        if args.debug_mode:
            print("="*50)
            print("ğŸ åµéŒ¯æ¨¡å¼å·²å•Ÿç”¨ - è¼¸å‡ºè©³ç´°æ—¥èªŒ")
            print("="*50)
            print(f"[DEBUG] ç’°å¢ƒè®Šé‡ï¼šTICKER={TICKER}, CACHE_DIR={CACHE_DIR}")
            print(f"[DEBUG] æ™‚é–“ç¯„åœï¼š{START_DATE} ~ {END_DATE}")
            print("="*50)

        # 3. åŸ·è¡Œæµç¨‹
        print("ğŸš€ é–‹å§‹é‹è¡Œç¨‹å¼...")
        df = fetch_and_cache_data(TICKER, START_DATE, END_DATE, CACHE_DIR, CACHE_FILE, HONG_KONG_TZ)
        processed_df = preprocess_data(df)
        plot_ohlc_chart(processed_df, TICKER)

        print("ğŸ‰ ç¨‹å¼åŸ·è¡ŒæˆåŠŸï¼")
        exit(0)

    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—ï¼š{str(e)}")
        exit(1)
